{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "(Solved_final)Car_Price_Prediction_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voXBKAC75Pi-"
      },
      "source": [
        "# Car Price Prediction::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_4l_xrv5Pjo"
      },
      "source": [
        "Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/hellbuoy/car-price-prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8g-XKdv5Pjs"
      },
      "source": [
        "# Problem Statement::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I233ZtJ5Pju"
      },
      "source": [
        "A Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n",
        "\n",
        "They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n",
        "\n",
        "Which variables are significant in predicting the price of a car\n",
        "How well those variables describe the price of a car\n",
        "Based on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n",
        "\n",
        "# task::\n",
        "We are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6eYxXpH5Pjx"
      },
      "source": [
        "# WORKFLOW ::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHGmlutB5Pjz"
      },
      "source": [
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "4.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "5.Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
        "6.Train the Model with Epochs (100) and validate it\n",
        "\n",
        "7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "8.Evaluation Step\n",
        "\n",
        "9.Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMNhsaH-5Pj2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "cars_data = pd.read_csv('CarPrice_Assignment.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQqtzlOj5Pj3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "1xhdGrJD5Pj4",
        "outputId": "344f2c75-38fc-4889-e8e1-0488cafa71ce"
      },
      "source": [
        "cars_data.head(7)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_ID</th>\n",
              "      <th>symboling</th>\n",
              "      <th>CarName</th>\n",
              "      <th>fueltype</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>doornumber</th>\n",
              "      <th>carbody</th>\n",
              "      <th>drivewheel</th>\n",
              "      <th>enginelocation</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginetype</th>\n",
              "      <th>cylindernumber</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>fuelsystem</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>alfa-romero giulia</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>dohc</td>\n",
              "      <td>four</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>13495.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>alfa-romero stelvio</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>dohc</td>\n",
              "      <td>four</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>alfa-romero Quadrifoglio</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>94.5</td>\n",
              "      <td>171.2</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "      <td>2823</td>\n",
              "      <td>ohcv</td>\n",
              "      <td>six</td>\n",
              "      <td>152</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>9.0</td>\n",
              "      <td>154</td>\n",
              "      <td>5000</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>audi 100 ls</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.8</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2337</td>\n",
              "      <td>ohc</td>\n",
              "      <td>four</td>\n",
              "      <td>109</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>audi 100ls</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.4</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2824</td>\n",
              "      <td>ohc</td>\n",
              "      <td>five</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>audi fox</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.8</td>\n",
              "      <td>177.3</td>\n",
              "      <td>66.3</td>\n",
              "      <td>53.1</td>\n",
              "      <td>2507</td>\n",
              "      <td>ohc</td>\n",
              "      <td>five</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>15250.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>audi 100ls</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>105.8</td>\n",
              "      <td>192.7</td>\n",
              "      <td>71.4</td>\n",
              "      <td>55.7</td>\n",
              "      <td>2844</td>\n",
              "      <td>ohc</td>\n",
              "      <td>five</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>17710.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   car_ID  symboling                   CarName  ... citympg highwaympg    price\n",
              "0       1          3        alfa-romero giulia  ...      21         27  13495.0\n",
              "1       2          3       alfa-romero stelvio  ...      21         27  16500.0\n",
              "2       3          1  alfa-romero Quadrifoglio  ...      19         26  16500.0\n",
              "3       4          2               audi 100 ls  ...      24         30  13950.0\n",
              "4       5          2                audi 100ls  ...      18         22  17450.0\n",
              "5       6          2                  audi fox  ...      19         25  15250.0\n",
              "6       7          1                audi 100ls  ...      19         25  17710.0\n",
              "\n",
              "[7 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOvfLIpg5Pj5",
        "outputId": "edb4320d-76b8-4cbe-86d0-afd580b3eb70"
      },
      "source": [
        "#check if there are empty cells#\n",
        "cars_data.isnull().any()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "car_ID              False\n",
              "symboling           False\n",
              "CarName             False\n",
              "fueltype            False\n",
              "aspiration          False\n",
              "doornumber          False\n",
              "carbody             False\n",
              "drivewheel          False\n",
              "enginelocation      False\n",
              "wheelbase           False\n",
              "carlength           False\n",
              "carwidth            False\n",
              "carheight           False\n",
              "curbweight          False\n",
              "enginetype          False\n",
              "cylindernumber      False\n",
              "enginesize          False\n",
              "fuelsystem          False\n",
              "boreratio           False\n",
              "stroke              False\n",
              "compressionratio    False\n",
              "horsepower          False\n",
              "peakrpm             False\n",
              "citympg             False\n",
              "highwaympg          False\n",
              "price               False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvllgFWm5Pj6",
        "outputId": "8a0748f9-39bd-43ca-e641-da8abeec9b0a"
      },
      "source": [
        "cars_data.dtypes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "car_ID                int64\n",
              "symboling             int64\n",
              "CarName              object\n",
              "fueltype             object\n",
              "aspiration           object\n",
              "doornumber           object\n",
              "carbody              object\n",
              "drivewheel           object\n",
              "enginelocation       object\n",
              "wheelbase           float64\n",
              "carlength           float64\n",
              "carwidth            float64\n",
              "carheight           float64\n",
              "curbweight            int64\n",
              "enginetype           object\n",
              "cylindernumber       object\n",
              "enginesize            int64\n",
              "fuelsystem           object\n",
              "boreratio           float64\n",
              "stroke              float64\n",
              "compressionratio    float64\n",
              "horsepower            int64\n",
              "peakrpm               int64\n",
              "citympg               int64\n",
              "highwaympg            int64\n",
              "price               float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgU3uu4e5Pj-"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV-SHNTJ59zT"
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "cars_data['fueltype'] = labelencoder.fit_transform(cars_data['fueltype'])\n",
        "cars_data['aspiration'] = labelencoder.fit_transform(cars_data['aspiration'])\n",
        "cars_data['doornumber'] = labelencoder.fit_transform(cars_data['doornumber'])\n",
        "cars_data['carbody'] = labelencoder.fit_transform(cars_data['carbody'])\n",
        "cars_data['drivewheel'] = labelencoder.fit_transform(cars_data['drivewheel'])\n",
        "cars_data['enginelocation'] = labelencoder.fit_transform(cars_data['enginelocation'])\n",
        "cars_data['enginetype'] = labelencoder.fit_transform(cars_data['enginetype'])\n",
        "cars_data['cylindernumber'] = labelencoder.fit_transform(cars_data['cylindernumber'])\n",
        "cars_data['fuelsystem'] = labelencoder.fit_transform(cars_data['fuelsystem'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "5HldMF9T6CAe",
        "outputId": "fc8cdfad-7da9-4026-cdcd-94e19322fa9c"
      },
      "source": [
        "cars_data.head(7)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_ID</th>\n",
              "      <th>symboling</th>\n",
              "      <th>CarName</th>\n",
              "      <th>fueltype</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>doornumber</th>\n",
              "      <th>carbody</th>\n",
              "      <th>drivewheel</th>\n",
              "      <th>enginelocation</th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginetype</th>\n",
              "      <th>cylindernumber</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>fuelsystem</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>alfa-romero giulia</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>5</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>13495.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>alfa-romero stelvio</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>5</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>alfa-romero Quadrifoglio</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>94.5</td>\n",
              "      <td>171.2</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "      <td>2823</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>152</td>\n",
              "      <td>5</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>9.0</td>\n",
              "      <td>154</td>\n",
              "      <td>5000</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>audi 100 ls</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>99.8</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2337</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>109</td>\n",
              "      <td>5</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>audi 100ls</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>99.4</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2824</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>136</td>\n",
              "      <td>5</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>audi fox</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>99.8</td>\n",
              "      <td>177.3</td>\n",
              "      <td>66.3</td>\n",
              "      <td>53.1</td>\n",
              "      <td>2507</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>136</td>\n",
              "      <td>5</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>15250.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>audi 100ls</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>105.8</td>\n",
              "      <td>192.7</td>\n",
              "      <td>71.4</td>\n",
              "      <td>55.7</td>\n",
              "      <td>2844</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>136</td>\n",
              "      <td>5</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>17710.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   car_ID  symboling                   CarName  ...  citympg  highwaympg    price\n",
              "0       1          3        alfa-romero giulia  ...       21          27  13495.0\n",
              "1       2          3       alfa-romero stelvio  ...       21          27  16500.0\n",
              "2       3          1  alfa-romero Quadrifoglio  ...       19          26  16500.0\n",
              "3       4          2               audi 100 ls  ...       24          30  13950.0\n",
              "4       5          2                audi 100ls  ...       18          22  17450.0\n",
              "5       6          2                  audi fox  ...       19          25  15250.0\n",
              "6       7          1                audi 100ls  ...       19          25  17710.0\n",
              "\n",
              "[7 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V7IvJjD6HDu",
        "outputId": "424d009f-6f4f-4fa3-ae60-1e34edaa74a9"
      },
      "source": [
        "cars_data.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['car_ID', 'symboling', 'CarName', 'fueltype', 'aspiration',\n",
              "       'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'wheelbase',\n",
              "       'carlength', 'carwidth', 'carheight', 'curbweight', 'enginetype',\n",
              "       'cylindernumber', 'enginesize', 'fuelsystem', 'boreratio', 'stroke',\n",
              "       'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg',\n",
              "       'price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9enHXWlO6KkI"
      },
      "source": [
        "cars_data.drop(columns=['car_ID','symboling', 'CarName', 'fueltype', 'aspiration', 'doornumber',\n",
        "       'carbody', 'drivewheel', 'enginelocation','enginetype', 'cylindernumber', 'fuelsystem' ], inplace = True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "ZvATQqOS6OVH",
        "outputId": "2b6edbc4-59f5-4149-ad27-a0d1f8ec1c1e"
      },
      "source": [
        "cars_data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wheelbase</th>\n",
              "      <th>carlength</th>\n",
              "      <th>carwidth</th>\n",
              "      <th>carheight</th>\n",
              "      <th>curbweight</th>\n",
              "      <th>enginesize</th>\n",
              "      <th>boreratio</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compressionratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peakrpm</th>\n",
              "      <th>citympg</th>\n",
              "      <th>highwaympg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>130</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>13495.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>88.6</td>\n",
              "      <td>168.8</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>2548</td>\n",
              "      <td>130</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94.5</td>\n",
              "      <td>171.2</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "      <td>2823</td>\n",
              "      <td>152</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>9.0</td>\n",
              "      <td>154</td>\n",
              "      <td>5000</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99.8</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2337</td>\n",
              "      <td>109</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>99.4</td>\n",
              "      <td>176.6</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "      <td>2824</td>\n",
              "      <td>136</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   wheelbase  carlength  carwidth  ...  citympg  highwaympg    price\n",
              "0       88.6      168.8      64.1  ...       21          27  13495.0\n",
              "1       88.6      168.8      64.1  ...       21          27  16500.0\n",
              "2       94.5      171.2      65.5  ...       19          26  16500.0\n",
              "3       99.8      176.6      66.2  ...       24          30  13950.0\n",
              "4       99.4      176.6      66.4  ...       18          22  17450.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRZ1eRmL6YrF"
      },
      "source": [
        "ready_data = cars_data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95s2GjEX6eAj",
        "outputId": "0c65c6cf-3a0f-4c1d-9658-ca80d133924b"
      },
      "source": [
        "ready_data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(205, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy1nERel6hEl"
      },
      "source": [
        "x = (ready_data.loc[:,ready_data.columns != 'price'])\n",
        "y = (ready_data.loc[:,ready_data.columns == 'price'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Swv6Je6lXx",
        "outputId": "bc440d2e-37d4-4939-9599-07522228317e"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(205, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVpqNymM6oXz",
        "outputId": "8d19ddf1-e499-427e-da71-8572f00448f5"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(205, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRfBFPtL6tNc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.70, random_state=42)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ5pBqp66xSh",
        "outputId": "3d40f1cf-b9a4-46d7-b26e-1474078cd077"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok04gzCC605s",
        "outputId": "eff09759-c5d4-49dc-894b-4207858a6a58"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtxjoXqh63ui"
      },
      "source": [
        "x.mean = x_train.mean(axis=0)\n",
        "x_train -= x.mean\n",
        "x.std = x_train.std(axis=0)\n",
        "x_train /= x.std\n",
        "x_test -= x.mean\n",
        "x_test /= x.std"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxiE1Wsy7qTn",
        "outputId": "a9e0d876-2a94-4431-a55b-bf4e55db6b06"
      },
      "source": [
        "x.mean"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wheelbase             98.930070\n",
              "carlength            174.655245\n",
              "carwidth              65.988811\n",
              "carheight             53.791608\n",
              "curbweight          2573.237762\n",
              "enginesize           127.013986\n",
              "boreratio              3.320559\n",
              "stroke                 3.257552\n",
              "compressionratio       9.983986\n",
              "horsepower           105.699301\n",
              "peakrpm             5154.545455\n",
              "citympg               24.818182\n",
              "highwaympg            30.321678\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nUUvwM-7_qb",
        "outputId": "c1a56817-bcd7-4fda-a6c0-a5702890969d"
      },
      "source": [
        "x.std"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wheelbase             6.073737\n",
              "carlength            12.407288\n",
              "carwidth              2.181939\n",
              "carheight             2.480075\n",
              "curbweight          522.368306\n",
              "enginesize           41.436526\n",
              "boreratio             0.272339\n",
              "stroke                0.307434\n",
              "compressionratio      3.745026\n",
              "horsepower           40.343950\n",
              "peakrpm             487.191907\n",
              "citympg               5.915647\n",
              "highwaympg            6.232131\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj3J3sGL8E2r"
      },
      "source": [
        "y.mean = y_train.mean(axis=0)\n",
        "y_train -= y.mean\n",
        "y.std = y_train.std(axis=0)\n",
        "y_train /= y.std\n",
        "y_test -= y.mean\n",
        "y_test /= y.std"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6uRoCSF8KBZ",
        "outputId": "56ac405c-9acc-4b57-8852-ea2e73844c52"
      },
      "source": [
        "y.mean"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "price    13408.503497\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P42hLZr28NQg",
        "outputId": "8a79fcaf-c58d-4dc6-9a9d-5abd1c5c1beb"
      },
      "source": [
        "y.std"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "price    7834.464872\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYTmDB_f8PpB",
        "outputId": "1461a8c4-62c7-4ac9-8388-923bcca173db"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpq_p1Ja8R-M"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "def build_model(abc):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(128, activation= abc , input_shape=(x_train.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation= abc ))\n",
        "    model.add(layers.Dense(32, activation= abc ))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGYSu1MA8YZ1",
        "outputId": "070fcc7f-7e4a-4c61-b0e8-7426a1b71535"
      },
      "source": [
        "build_model"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.build_model>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ypBNYs68bwK",
        "outputId": "419bdf74-4a7c-4467-863e-bd10f677d864"
      },
      "source": [
        "build_model('relu').summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 12,161\n",
            "Trainable params: 12,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFTx3Mbw8fWF",
        "outputId": "cc551a07-4748-410e-cbf2-230a27590f26"
      },
      "source": [
        "build_model('tanh').summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 12,161\n",
            "Trainable params: 12,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWFZJBZh8xf6"
      },
      "source": [
        "**k fold validation with relu**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8g06BZh88ya"
      },
      "source": [
        "k = 4\n",
        "num_val_samples = len(x_train) // k\n",
        "num_epochs = 100\n",
        "all_scores = []"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e9PzUph9Gex",
        "outputId": "d125cf3e-d9ff-4e15-f0d8-1a4762066a54"
      },
      "source": [
        "all_mae_histories_relu = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate([x_train[:i * num_val_samples],\n",
        "        x_train[(i + 1) * num_val_samples:]],axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [y_train[:i * num_val_samples],\n",
        "        y_train[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model('relu')\n",
        "    history_relu =model.fit(partial_train_data, partial_train_targets,\n",
        "        epochs=num_epochs, batch_size=1, verbose=1)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)\n",
        "    mae_history_relu = history_relu.history['mae']\n",
        "    all_mae_histories_relu.append(mae_history_relu)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.4275 - mae: 0.4929\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1473 - mae: 0.2691\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1095 - mae: 0.2137\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0867 - mae: 0.2136\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0622 - mae: 0.1766\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0682 - mae: 0.1906\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0696 - mae: 0.1888\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0826 - mae: 0.1974\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0311 - mae: 0.1278\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0388 - mae: 0.1524\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0633 - mae: 0.1466\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0421 - mae: 0.1388\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0475 - mae: 0.1587\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0405 - mae: 0.1438\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0394 - mae: 0.1371\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0451 - mae: 0.1360\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0330 - mae: 0.1212\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0377 - mae: 0.1328\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0285 - mae: 0.1209\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0386 - mae: 0.1297\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0289 - mae: 0.1125\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1045 - mae: 0.1801\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0387 - mae: 0.1312\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0404 - mae: 0.1350\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1100\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0334 - mae: 0.1073\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0328 - mae: 0.1241\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0478 - mae: 0.1265\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0252 - mae: 0.1156\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.1170\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.0989\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0228 - mae: 0.0978\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0304 - mae: 0.1295\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.1108\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0415 - mae: 0.1264\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0335 - mae: 0.1303\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.0992\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.1161\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0391 - mae: 0.1243\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0354 - mae: 0.1411\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0311 - mae: 0.1088\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0176 - mae: 0.0949\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0296 - mae: 0.1050\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.1022\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0255 - mae: 0.1126\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0226 - mae: 0.1050\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.0906\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0258 - mae: 0.1097\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.1259\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.1030\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0248 - mae: 0.1028\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0226 - mae: 0.1088\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0139 - mae: 0.0805\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0232 - mae: 0.1019\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0150 - mae: 0.0829\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0194 - mae: 0.0933\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0519 - mae: 0.1336\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.1237\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0312 - mae: 0.1215\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0155 - mae: 0.0840\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0251 - mae: 0.1019\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0147 - mae: 0.0859\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0292 - mae: 0.1094\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0215 - mae: 0.1072\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0255 - mae: 0.1190\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0280 - mae: 0.1122\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1080\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.1144\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0862\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.0852\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0815\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0240 - mae: 0.1045\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0140 - mae: 0.0777\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0234 - mae: 0.1080\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0759\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0158 - mae: 0.0892\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0116 - mae: 0.0794\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0268 - mae: 0.1084\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0218 - mae: 0.0950\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0224 - mae: 0.0996\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0267 - mae: 0.1099\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0921\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0230 - mae: 0.0939\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0294 - mae: 0.1059\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0183 - mae: 0.0871\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0155 - mae: 0.0818\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0930\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0236 - mae: 0.0988\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0306 - mae: 0.0976\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0189 - mae: 0.0919\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0316 - mae: 0.1051\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0150 - mae: 0.0802\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0223 - mae: 0.0982\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0169 - mae: 0.0875\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0153 - mae: 0.0888\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0184 - mae: 0.0938\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0349 - mae: 0.1242\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0163 - mae: 0.0814\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0960\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0202 - mae: 0.0861\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.5499 - mae: 0.5316\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1510 - mae: 0.2725\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1206 - mae: 0.2336\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0806 - mae: 0.1919\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0991 - mae: 0.2285\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0805 - mae: 0.1905\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0526 - mae: 0.1560\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0850 - mae: 0.1920\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0545 - mae: 0.1560\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0630 - mae: 0.1569\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0439 - mae: 0.1430\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0384 - mae: 0.1277\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0432 - mae: 0.1438\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0432 - mae: 0.1506\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0315 - mae: 0.1219\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0330 - mae: 0.1173\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0413 - mae: 0.1335\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0529 - mae: 0.1444\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1226 - mae: 0.1878\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0348 - mae: 0.1271\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0380 - mae: 0.1187\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0332 - mae: 0.1206\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0284 - mae: 0.1239\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0376 - mae: 0.1284\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0286 - mae: 0.1135\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0350 - mae: 0.1303\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1075\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0343 - mae: 0.1096\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0406 - mae: 0.1349\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0260 - mae: 0.0998\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0138 - mae: 0.0843\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0329 - mae: 0.1137\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0365 - mae: 0.1004\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0326 - mae: 0.1182\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0238 - mae: 0.1003\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0297 - mae: 0.1102\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0253 - mae: 0.1099\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.1033\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0278 - mae: 0.1173\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0411 - mae: 0.1194\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0929\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0286 - mae: 0.1044\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0282 - mae: 0.1021\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0322 - mae: 0.1070\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0202 - mae: 0.0944\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0908\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0227 - mae: 0.1073\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.0899\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0427 - mae: 0.1260\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.1041\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0183 - mae: 0.0829\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.1109\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0135 - mae: 0.0702\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0264 - mae: 0.0967\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.0992\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0201 - mae: 0.0928\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0154 - mae: 0.0826\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0133 - mae: 0.0807\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0301 - mae: 0.1086\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0146 - mae: 0.0818\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0112 - mae: 0.0770\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0211 - mae: 0.0949\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0148 - mae: 0.0879\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0978\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0240 - mae: 0.0948\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0396 - mae: 0.1190\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0178 - mae: 0.0941\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0180 - mae: 0.0866\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.1046\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0157 - mae: 0.0831\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0236 - mae: 0.0791\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0233 - mae: 0.0920\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0844\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0259 - mae: 0.0942\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0112 - mae: 0.0757\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0147 - mae: 0.0873\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0281 - mae: 0.0969\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0475 - mae: 0.1141\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0153 - mae: 0.0771\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0270 - mae: 0.0990\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0128 - mae: 0.0761\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0109 - mae: 0.0779\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.1013\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0156 - mae: 0.0706\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0163 - mae: 0.0797\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.0743\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0916\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.0904\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0224 - mae: 0.0983\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0224 - mae: 0.0955\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0143 - mae: 0.0817\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0143 - mae: 0.0771\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0117 - mae: 0.0733\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0145 - mae: 0.0768\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.0877\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0179 - mae: 0.0912\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0138 - mae: 0.0777\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0278 - mae: 0.0997\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0184 - mae: 0.0881\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0224 - mae: 0.1096\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.6078 - mae: 0.4887\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1283 - mae: 0.2381\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0990 - mae: 0.2256\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0680 - mae: 0.1985\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0814 - mae: 0.2026\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0816 - mae: 0.1888\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0942 - mae: 0.2065\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0898 - mae: 0.1926\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0512 - mae: 0.1645\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0541 - mae: 0.1613\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0463 - mae: 0.1576\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0319 - mae: 0.1325\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0513 - mae: 0.1431\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0341 - mae: 0.1241\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0571 - mae: 0.1613\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0411 - mae: 0.1425\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0203 - mae: 0.1027\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0227 - mae: 0.0942\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0145 - mae: 0.0808\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.1222\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0201 - mae: 0.0961\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0235 - mae: 0.1090\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0357 - mae: 0.1220\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0208 - mae: 0.1025\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1013\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0210 - mae: 0.0938\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0248 - mae: 0.1097\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0169 - mae: 0.0891\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0283 - mae: 0.0988\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0265 - mae: 0.0935\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0160 - mae: 0.0920\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0462 - mae: 0.1347\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0211 - mae: 0.1037\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0944\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0160 - mae: 0.0955\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.1081\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0887\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.0973\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0189 - mae: 0.0914\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.0968\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0226 - mae: 0.1040\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.0855\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0313 - mae: 0.1121\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0811\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0189 - mae: 0.0950\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0230 - mae: 0.1044\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.0861\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0216 - mae: 0.1088\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0356 - mae: 0.1048\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0219 - mae: 0.1027\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0165 - mae: 0.0904\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.0994\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.0820\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0208 - mae: 0.0959\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0126 - mae: 0.0780\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0249 - mae: 0.0977\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0166 - mae: 0.0892\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0179 - mae: 0.0878\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0202 - mae: 0.0943\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0793\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0230 - mae: 0.1094\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0189 - mae: 0.0922\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0129 - mae: 0.0777\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0155 - mae: 0.0851\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0201 - mae: 0.0898\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.1033\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0281 - mae: 0.0926\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0120 - mae: 0.0742\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0128 - mae: 0.0805\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0308 - mae: 0.1119\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0191 - mae: 0.0731\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0183 - mae: 0.0895\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.0837\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0126 - mae: 0.0750\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0155 - mae: 0.0820\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0276 - mae: 0.1051\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0115 - mae: 0.0738\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0191 - mae: 0.0928\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0107 - mae: 0.0698\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0296 - mae: 0.0991\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0226 - mae: 0.0919\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0236 - mae: 0.0889\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0154 - mae: 0.0842\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0656\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0160 - mae: 0.0849\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0151 - mae: 0.0854\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0189 - mae: 0.0923\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0859\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0145 - mae: 0.0764\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0862\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0135 - mae: 0.0758\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0866\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0187 - mae: 0.0842\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0124 - mae: 0.0786\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0142 - mae: 0.0785\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0113 - mae: 0.0644\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0136 - mae: 0.0853\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0196 - mae: 0.0929\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0749\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0139 - mae: 0.0764\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.4728 - mae: 0.4407\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1030 - mae: 0.2099\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1071 - mae: 0.2157\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1212 - mae: 0.2278\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0640 - mae: 0.1782\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0882 - mae: 0.1922\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0462 - mae: 0.1590\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0569 - mae: 0.1602\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0646 - mae: 0.1514\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0520 - mae: 0.1522\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0428 - mae: 0.1419\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0347 - mae: 0.1318\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0351 - mae: 0.1340\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0462 - mae: 0.1568\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0344 - mae: 0.1325\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0766 - mae: 0.1554\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0432 - mae: 0.1416\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0227 - mae: 0.1128\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0579 - mae: 0.1327\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0252 - mae: 0.1097\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0424 - mae: 0.1275\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0296 - mae: 0.1093\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.1032\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.1227\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0529 - mae: 0.1441\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0251 - mae: 0.1053\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0243 - mae: 0.1116\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0308 - mae: 0.1243\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0194 - mae: 0.1040\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0373 - mae: 0.1257\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0230 - mae: 0.0975\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0178 - mae: 0.1015\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0163 - mae: 0.0979\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0166 - mae: 0.0946\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0424 - mae: 0.1381\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0232 - mae: 0.1085\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.1054\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0334 - mae: 0.1103\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.1021\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0307 - mae: 0.1199\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0272 - mae: 0.1139\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.1186\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0197 - mae: 0.0972\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0348 - mae: 0.1073\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0258 - mae: 0.1137\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0261 - mae: 0.1060\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.0996\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0198 - mae: 0.0912\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0187 - mae: 0.0885\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0137 - mae: 0.0854\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0193 - mae: 0.0932\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0222 - mae: 0.0990\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0216 - mae: 0.0927\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0443 - mae: 0.1109\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0123 - mae: 0.0804\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0132 - mae: 0.0848\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0917\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.1017\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0415 - mae: 0.1367\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.0859\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0941\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0190 - mae: 0.0909\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0801\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0916\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.0782\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.0944\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0221 - mae: 0.1044\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.1023\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0829\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0235 - mae: 0.0923\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.0918\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0256 - mae: 0.0986\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0154 - mae: 0.0888\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0294 - mae: 0.1048\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0702\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0254 - mae: 0.0998\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0158 - mae: 0.0888\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0175 - mae: 0.0916\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0108 - mae: 0.0720\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0111 - mae: 0.0792\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0106 - mae: 0.0674\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0106 - mae: 0.0722\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0837\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0177 - mae: 0.0977\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.0985\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0128 - mae: 0.0741\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0087 - mae: 0.0643\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0160 - mae: 0.0814\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.0832\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0261 - mae: 0.0914\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0804\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0123 - mae: 0.0780\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0214 - mae: 0.0869\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0112 - mae: 0.0808\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0165 - mae: 0.0880\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0879\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0645\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0212 - mae: 0.0968\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0286 - mae: 0.1015\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0181 - mae: 0.0832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thmwwt4Q-RFp"
      },
      "source": [
        "average_mae_history_relu = [np.mean([x[i] for x in all_mae_histories_relu]) for i in range(num_epochs)]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "n2kpt2pq_XBo",
        "outputId": "bace9a52-7f6a-4ee8-b9f0-543139e92a1e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, len(average_mae_history_relu) + 1), average_mae_history_relu)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hskoOckw-lY3"
      },
      "source": [
        "# K fold function with **tahn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Pq5AVe-m5_"
      },
      "source": [
        "k = 4\n",
        "num_val_samples = len(x_train) // k\n",
        "num_epochs = 100\n",
        "all_scores_tahn = []"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPitrT2s-uPv",
        "outputId": "125c9a20-1e91-42ce-e98c-397b70f82566"
      },
      "source": [
        "all_mae_histories_tanh = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate([x_train[:i * num_val_samples],\n",
        "        x_train[(i + 1) * num_val_samples:]],axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [y_train[:i * num_val_samples],\n",
        "        y_train[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model('tanh')\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "        epochs=num_epochs, batch_size=1, verbose=1)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
        "    all_scores_tahn.append(val_mae)\n",
        "    mae_history = history.history['mae']\n",
        "    all_mae_histories_tanh.append(mae_history)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.7678 - mae: 0.6306\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.3049 - mae: 0.4261\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2896 - mae: 0.4036\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2417 - mae: 0.3803\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1462 - mae: 0.2802\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2155 - mae: 0.3633\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1418 - mae: 0.2753\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1181 - mae: 0.2722\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1835 - mae: 0.3153\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1076 - mae: 0.2467\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1087 - mae: 0.2469\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0916 - mae: 0.2361\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1337 - mae: 0.2464\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0835 - mae: 0.2064\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0691 - mae: 0.1917\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0678 - mae: 0.1976\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0629 - mae: 0.1957\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0717 - mae: 0.1978\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0640 - mae: 0.1890\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0672 - mae: 0.2082\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0817 - mae: 0.2078\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0533 - mae: 0.1689\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0712 - mae: 0.2088\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0528 - mae: 0.1781\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0420 - mae: 0.1607\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0606 - mae: 0.1624\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0533 - mae: 0.1687\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0387 - mae: 0.1515\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0519 - mae: 0.1648\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0397 - mae: 0.1443\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0792 - mae: 0.1842\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0675 - mae: 0.1918\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0790 - mae: 0.1885\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0370 - mae: 0.1537\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0598 - mae: 0.1817\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0569 - mae: 0.1863\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0535 - mae: 0.1775\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0313 - mae: 0.1373\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0525 - mae: 0.1683\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0528 - mae: 0.1532\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0369 - mae: 0.1462\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0410 - mae: 0.1469\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0355 - mae: 0.1295\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0381 - mae: 0.1507\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0396 - mae: 0.1452\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0414 - mae: 0.1536\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0533 - mae: 0.1717\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0267 - mae: 0.1062\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0270 - mae: 0.1184\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0567 - mae: 0.1529\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0313 - mae: 0.1311\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0367 - mae: 0.1404\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0385 - mae: 0.1461\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0232 - mae: 0.1192\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0388 - mae: 0.1518\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0384 - mae: 0.1395\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0278 - mae: 0.1292\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0365 - mae: 0.1237\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0384 - mae: 0.1420\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0268 - mae: 0.1140\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0442 - mae: 0.1438\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0303 - mae: 0.1191\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0330 - mae: 0.1403\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0288 - mae: 0.1164\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0311 - mae: 0.1243\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.1185\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0204 - mae: 0.1063\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0341 - mae: 0.1363\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0285 - mae: 0.1314\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0375 - mae: 0.1347\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0233 - mae: 0.1164\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.1175\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1184\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0370 - mae: 0.1222\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0190 - mae: 0.1009\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0339 - mae: 0.1378\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0342 - mae: 0.1354\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0190 - mae: 0.1062\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0280 - mae: 0.1141\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0275 - mae: 0.1115\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.1224\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0212 - mae: 0.1090\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0176 - mae: 0.0932\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0226 - mae: 0.1142\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0214 - mae: 0.1019\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0968\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0164 - mae: 0.0912\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0248 - mae: 0.1084\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0995\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0267 - mae: 0.1152\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0189 - mae: 0.0955\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0149 - mae: 0.0904\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0298 - mae: 0.1150\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0358 - mae: 0.1419\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0290 - mae: 0.1153\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0204 - mae: 0.0997\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.0993\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0218 - mae: 0.1106\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0196 - mae: 0.1005\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.0942\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87d5587c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0741 - mae: 0.2125\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.5627 - mae: 0.5702\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2454 - mae: 0.3433\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2025 - mae: 0.3441\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2172 - mae: 0.3403\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1190 - mae: 0.2358\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1083 - mae: 0.2328\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1414 - mae: 0.2936\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1685 - mae: 0.3035\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0930 - mae: 0.2172\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1238 - mae: 0.2717\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0883 - mae: 0.2219\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0891 - mae: 0.2308\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0899 - mae: 0.2218\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0997 - mae: 0.2263\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0633 - mae: 0.2049\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0612 - mae: 0.1764\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0625 - mae: 0.1804\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0421 - mae: 0.1500\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0545 - mae: 0.1725\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0535 - mae: 0.1662\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0512 - mae: 0.1758\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0410 - mae: 0.1534\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0506 - mae: 0.1705\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0503 - mae: 0.1583\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0563 - mae: 0.1681\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0333 - mae: 0.1368\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0296 - mae: 0.1247\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0601 - mae: 0.1770\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0360 - mae: 0.1506\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0432 - mae: 0.1675\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0315 - mae: 0.1456\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0366 - mae: 0.1440\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0600 - mae: 0.1704\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0330 - mae: 0.1429\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0232 - mae: 0.1119\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0268 - mae: 0.1262\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0292 - mae: 0.1297\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.1127\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0272 - mae: 0.1143\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0420 - mae: 0.1575\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0335 - mae: 0.1361\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.1193\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0267 - mae: 0.1242\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0357 - mae: 0.1431\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0367 - mae: 0.1282\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0380 - mae: 0.1434\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0250 - mae: 0.1184\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0282 - mae: 0.1282\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0331 - mae: 0.1202\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0177 - mae: 0.1050\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0171 - mae: 0.0984\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0158 - mae: 0.0953\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.1086\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.1115\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0192 - mae: 0.1076\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0246 - mae: 0.1076\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0240 - mae: 0.1038\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0236 - mae: 0.1184\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0275 - mae: 0.1150\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0195 - mae: 0.1015\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0188 - mae: 0.1000\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0287 - mae: 0.1251\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.0937\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0248 - mae: 0.1095\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0238 - mae: 0.0987\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0318 - mae: 0.1105\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.1112\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0211 - mae: 0.1116\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0219 - mae: 0.1045\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0219 - mae: 0.1063\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0972\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0203 - mae: 0.1033\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0160 - mae: 0.0869\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0126 - mae: 0.0863\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0256 - mae: 0.0989\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0868\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0137 - mae: 0.0856\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0142 - mae: 0.0800\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.1026\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0249 - mae: 0.1120\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0223 - mae: 0.1043\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0156 - mae: 0.0947\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.1056\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0146 - mae: 0.0925\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0155 - mae: 0.0958\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1184\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0985\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0127 - mae: 0.0875\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0143 - mae: 0.0890\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0261 - mae: 0.1008\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0881\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0977\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0126 - mae: 0.0799\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0764\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0278 - mae: 0.1143\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0117 - mae: 0.0840\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0158 - mae: 0.1005\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0135 - mae: 0.0849\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0125 - mae: 0.0799\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0164 - mae: 0.0870\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cf83a9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2758 - mae: 0.3329\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.7566 - mae: 0.5847\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.3230 - mae: 0.3498\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2217 - mae: 0.3165\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1620 - mae: 0.2891\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1749 - mae: 0.2665\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1444 - mae: 0.2761\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1612 - mae: 0.2788\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0827 - mae: 0.2036\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0725 - mae: 0.1978\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0725 - mae: 0.2040\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1062 - mae: 0.2547\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0543 - mae: 0.1802\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0521 - mae: 0.1674\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0653 - mae: 0.1938\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0481 - mae: 0.1629\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0506 - mae: 0.1595\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0664 - mae: 0.1901\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0674 - mae: 0.1874\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0451 - mae: 0.1641\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0446 - mae: 0.1692\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0423 - mae: 0.1513\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0445 - mae: 0.1600\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0462 - mae: 0.1641\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0399 - mae: 0.1574\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.1271\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0322 - mae: 0.1185\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0519 - mae: 0.1655\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0470 - mae: 0.1689\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0431 - mae: 0.1558\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0253 - mae: 0.1190\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0456 - mae: 0.1547\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0312 - mae: 0.1403\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0403 - mae: 0.1483\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0467 - mae: 0.1634\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0307 - mae: 0.1379\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0265 - mae: 0.1228\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0305 - mae: 0.1297\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0286 - mae: 0.1325\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.1196\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0315 - mae: 0.1318\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0367 - mae: 0.1427\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0395 - mae: 0.1265\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0253 - mae: 0.1263\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0256 - mae: 0.1125\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0324 - mae: 0.1286\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0310 - mae: 0.1210\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0288 - mae: 0.1317\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0376 - mae: 0.1402\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0294 - mae: 0.1307\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0304 - mae: 0.1377\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0223 - mae: 0.1222\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.0965\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0226 - mae: 0.1165\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0295 - mae: 0.1207\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.1188\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0265 - mae: 0.1282\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0285 - mae: 0.1369\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0361 - mae: 0.1282\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.1112\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0231 - mae: 0.1131\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0136 - mae: 0.0874\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0255 - mae: 0.1165\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.1068\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0259 - mae: 0.1177\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0301 - mae: 0.1225\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0214 - mae: 0.1180\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0210 - mae: 0.1012\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0249 - mae: 0.1055\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0194 - mae: 0.1037\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0235 - mae: 0.1137\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0292 - mae: 0.1311\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0190 - mae: 0.1055\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0221 - mae: 0.1051\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0175 - mae: 0.0941\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0928\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.1223\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0238 - mae: 0.1204\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0300 - mae: 0.1147\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0227 - mae: 0.0931\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0257 - mae: 0.1200\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0141 - mae: 0.0834\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0200 - mae: 0.0979\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0191 - mae: 0.0941\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0145 - mae: 0.0851\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0256 - mae: 0.1306\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0362 - mae: 0.1172\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0254 - mae: 0.1186\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0909\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0237 - mae: 0.1119\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.1147\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0226 - mae: 0.1191\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.1084\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.1019\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0189 - mae: 0.0988\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0139 - mae: 0.0887\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0295 - mae: 0.1214\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0233 - mae: 0.1069\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0165 - mae: 0.0922\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0920\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0940\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87ceb01b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2933 - mae: 0.3240\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.5545 - mae: 0.5307\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.3145 - mae: 0.4135\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1934 - mae: 0.3382\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1869 - mae: 0.2963\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1623 - mae: 0.2923\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1294 - mae: 0.2614\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1167 - mae: 0.2498\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1177 - mae: 0.2494\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0744 - mae: 0.1975\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0846 - mae: 0.2135\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0993 - mae: 0.2221\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1333 - mae: 0.2458\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0575 - mae: 0.1785\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0468 - mae: 0.1638\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0542 - mae: 0.1702\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0622 - mae: 0.1926\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0561 - mae: 0.1704\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0486 - mae: 0.1796\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0504 - mae: 0.1548\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0499 - mae: 0.1707\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0484 - mae: 0.1573\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0467 - mae: 0.1618\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0307 - mae: 0.1367\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0384 - mae: 0.1605\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0393 - mae: 0.1413\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1355\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0414 - mae: 0.1639\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0293 - mae: 0.1376\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0214 - mae: 0.1147\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0311 - mae: 0.1364\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.1292\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0337 - mae: 0.1493\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0289 - mae: 0.1179\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0392 - mae: 0.1554\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.1286\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.1199\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.1137\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0958\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.1084\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.1117\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0183 - mae: 0.1052\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0232 - mae: 0.1252\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0330 - mae: 0.1335\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0196 - mae: 0.1141\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0224 - mae: 0.1145\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0145 - mae: 0.0952\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0124 - mae: 0.0873\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0212 - mae: 0.1063\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0236 - mae: 0.1171\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0143 - mae: 0.0936\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0232 - mae: 0.1100\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0189 - mae: 0.0961\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0141 - mae: 0.0875\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.1109\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0140 - mae: 0.0870\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0184 - mae: 0.1036\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.1058\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.1095\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0133 - mae: 0.0914\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0206 - mae: 0.1157\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0188 - mae: 0.1073\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0123 - mae: 0.0932\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0225 - mae: 0.1266\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0117 - mae: 0.0828\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0142 - mae: 0.0884\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0151 - mae: 0.0872\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.0966\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0160 - mae: 0.0988\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.1050\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0195 - mae: 0.1084\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0146 - mae: 0.0925\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0745\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0164 - mae: 0.1010\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0109 - mae: 0.0822\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0923\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0119 - mae: 0.0825\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0125 - mae: 0.0852\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0169 - mae: 0.0988\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0947\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0139 - mae: 0.0920\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0136 - mae: 0.0839\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0135 - mae: 0.0930\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0105 - mae: 0.0808\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.0914\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0825\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0130 - mae: 0.0890\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0153 - mae: 0.0926\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0830\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0096 - mae: 0.0713\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0094 - mae: 0.0757\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0175 - mae: 0.0981\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0115 - mae: 0.0778\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0125 - mae: 0.0909\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0085 - mae: 0.0728\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0822\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0746\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0115 - mae: 0.0750\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0117 - mae: 0.0814\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0142 - mae: 0.0929\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0690\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87ceb01320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2099 - mae: 0.2964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIQXKTww-zad"
      },
      "source": [
        "average_mae_history_tanh = [np.mean([x[i] for x in all_mae_histories_tanh]) for i in range(num_epochs)]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "0e23AOXO_Ace",
        "outputId": "35a09ac8-f1de-4427-db15-2f291b996c0b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, len(average_mae_history_tanh) + 1), average_mae_history_tanh)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSrU9QidAiY_"
      },
      "source": [
        "# Regularized model\n",
        "from tensorflow.keras import regularizers\n",
        "def build_model_regular(act):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(10, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001),input_shape=(x_train.shape[1],)))\n",
        "    model.add(layers.Dense(8, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
        "    model.add(layers.Dense(6, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaZ4TOJsCzaU",
        "outputId": "3ced9771-85fd-4212-fd1f-a41653b8ddf3"
      },
      "source": [
        "build_model_regular('tanh').summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_40 (Dense)             (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 289\n",
            "Trainable params: 289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiO3eS3JDRWy"
      },
      "source": [
        "# K fold function with **regularizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eodj5aADDSVa"
      },
      "source": [
        "k = 4\n",
        "num_val_samples = len(x_train) // k\n",
        "num_epochs = 100\n",
        "all_scores_regul = []"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6UjOImrDxHT",
        "outputId": "33ecb559-c9a6-4cd4-d8fd-c896c1340b73"
      },
      "source": [
        "all_mae_histories_regul = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate([x_train[:i * num_val_samples],\n",
        "        x_train[(i + 1) * num_val_samples:]],axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [y_train[:i * num_val_samples],\n",
        "        y_train[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model('tanh')\n",
        "    history_regul = model.fit(partial_train_data, partial_train_targets,\n",
        "        epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
        "    all_scores_regul.append(val_mae)\n",
        "    mae_history_regul = history_regul.history['mae']\n",
        "    all_mae_histories_regul.append(mae_history_regul)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87f0eaf290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1010 - mae: 0.2645\n",
            "processing fold # 1\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cd7f1710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2669 - mae: 0.3514\n",
            "processing fold # 2\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cef8a9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4463 - mae: 0.3821\n",
            "processing fold # 3\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87d247b200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2261 - mae: 0.3303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm6CUpaDESf2"
      },
      "source": [
        "average_mae_history_regul = [np.mean([x[i] for x in all_mae_histories_regul]) for i in range(num_epochs)]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "uPP3MYuTFA5q",
        "outputId": "e65c5912-6229-44d5-aa75-8aff94b29fce"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, len(average_mae_history_regul) + 1), average_mae_history_regul)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8zYs27BFJWj"
      },
      "source": [
        "# dropout model\n",
        "from tensorflow.keras import regularizers\n",
        "def build_model_drop(act):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(10, activation= act,input_shape=(x_train.shape[1],)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(8, activation= act))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(6, activation= act))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHwlX2m4Fdwq",
        "outputId": "a1a795aa-fd57-4ce4-98ea-5bd3d966da3f"
      },
      "source": [
        "build_model_drop('relu').summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_76 (Dense)             (None, 10)                140       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 289\n",
            "Trainable params: 289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MgZ8_1hGGdF"
      },
      "source": [
        "# K fold function with **dropout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQt2ZNQxGIXt"
      },
      "source": [
        "k = 4\n",
        "num_val_samples = len(x_train) // k\n",
        "num_epochs = 100\n",
        "all_scores_drop = []"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr_JghzQGiHG",
        "outputId": "9bd6f661-d199-4ed2-9e07-56e3f91d93a0"
      },
      "source": [
        "all_mae_histories_drop = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    val_data = x_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate([x_train[:i * num_val_samples],\n",
        "        x_train[(i + 1) * num_val_samples:]],axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [y_train[:i * num_val_samples],\n",
        "        y_train[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model('relu')\n",
        "    history_drop = model.fit(partial_train_data, partial_train_targets,\n",
        "        epochs=num_epochs, batch_size=1, verbose=1)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=1)\n",
        "    all_scores_drop.append(val_mae)\n",
        "    mae_history_drop = history_drop.history['mae']\n",
        "    all_mae_histories_drop.append(mae_history_drop)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.8769 - mae: 0.5743\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2671 - mae: 0.3388\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1711 - mae: 0.2906\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0941 - mae: 0.2144\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0976 - mae: 0.2252\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0778 - mae: 0.1803\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0877 - mae: 0.1923\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0524 - mae: 0.1608\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0804 - mae: 0.1927\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0433 - mae: 0.1282\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0495 - mae: 0.1602\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0658 - mae: 0.1643\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0534 - mae: 0.1552\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0431 - mae: 0.1506\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0531 - mae: 0.1500\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0397 - mae: 0.1321\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0384 - mae: 0.1382\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.1373\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0392 - mae: 0.1292\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0394 - mae: 0.1309\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.1237\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0393 - mae: 0.1310\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0769 - mae: 0.1608\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0512 - mae: 0.1386\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0292 - mae: 0.1160\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0513 - mae: 0.1610\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0380 - mae: 0.1273\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0377 - mae: 0.1275\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0257 - mae: 0.1057\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0309 - mae: 0.1333\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.1254\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0424 - mae: 0.1433\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0311 - mae: 0.1188\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0305 - mae: 0.1182\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0190 - mae: 0.1017\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0212 - mae: 0.1058\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0332 - mae: 0.1203\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.1171\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0350 - mae: 0.1299\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0351 - mae: 0.1130\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0236 - mae: 0.1045\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0996\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0285 - mae: 0.0959\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0233 - mae: 0.1151\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0236 - mae: 0.1070\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0249 - mae: 0.1088\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0165 - mae: 0.0908\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0293 - mae: 0.1095\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0264 - mae: 0.0975\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0272 - mae: 0.1084\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0415 - mae: 0.1208\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0398 - mae: 0.1343\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0896\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0399 - mae: 0.1182\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0187 - mae: 0.0971\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0221 - mae: 0.0996\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0254 - mae: 0.1094\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0313 - mae: 0.1170\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0151 - mae: 0.0897\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0210 - mae: 0.1003\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0264 - mae: 0.1161\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0143 - mae: 0.0787\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0201 - mae: 0.0870\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0225 - mae: 0.1060\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0238 - mae: 0.0954\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0934\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0257 - mae: 0.1055\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0311 - mae: 0.1071\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.1023\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0221 - mae: 0.0891\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0326 - mae: 0.1076\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.1014\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0881\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.0907\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0252 - mae: 0.1099\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.0988\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0288 - mae: 0.1019\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.0980\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1052\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0265 - mae: 0.1039\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0230 - mae: 0.1051\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0146 - mae: 0.0852\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0559 - mae: 0.1228\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0301 - mae: 0.1164\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0193 - mae: 0.0888\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0829\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0819\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0762\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0195 - mae: 0.0941\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0164 - mae: 0.0932\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0204 - mae: 0.0924\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0133 - mae: 0.0770\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.0973\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0217 - mae: 0.0957\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0113 - mae: 0.0742\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0223 - mae: 0.0869\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0275 - mae: 0.1046\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.0988\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0130 - mae: 0.0823\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0201 - mae: 0.0932\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cd8daa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0592 - mae: 0.1944\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.5657 - mae: 0.5378\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1813 - mae: 0.2880\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1005 - mae: 0.2167\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1125 - mae: 0.2323\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0999 - mae: 0.2137\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0707 - mae: 0.1639\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0575 - mae: 0.1653\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0445 - mae: 0.1441\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0469 - mae: 0.1612\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0566 - mae: 0.1604\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0362 - mae: 0.1190\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0356 - mae: 0.1352\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0379 - mae: 0.1404\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0569 - mae: 0.1502\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0736 - mae: 0.1688\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0606 - mae: 0.1713\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.1192\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0490 - mae: 0.1409\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0446 - mae: 0.1378\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0243 - mae: 0.1163\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0290 - mae: 0.1120\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0264 - mae: 0.1141\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0265 - mae: 0.1115\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0253 - mae: 0.1152\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0325 - mae: 0.1079\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.1098\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0454 - mae: 0.1250\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0246 - mae: 0.1081\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0261 - mae: 0.1010\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0397 - mae: 0.1229\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0258 - mae: 0.1068\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0385 - mae: 0.1294\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.1067\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0194 - mae: 0.0993\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0378 - mae: 0.1185\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0249 - mae: 0.1136\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.0875\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0217 - mae: 0.0958\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0221 - mae: 0.1060\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.0914\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0184 - mae: 0.0997\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0492 - mae: 0.1269\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0298 - mae: 0.0968\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0177 - mae: 0.0888\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0233 - mae: 0.1090\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0249 - mae: 0.0940\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0531 - mae: 0.1223\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0290 - mae: 0.1078\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0164 - mae: 0.0835\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0222 - mae: 0.0944\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0182 - mae: 0.0947\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.0888\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0265 - mae: 0.1134\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0164 - mae: 0.0823\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0126 - mae: 0.0767\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0262 - mae: 0.1129\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0902\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0183 - mae: 0.0924\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0122 - mae: 0.0717\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0204 - mae: 0.0862\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0164 - mae: 0.0854\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0374 - mae: 0.1019\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0918\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0230 - mae: 0.1000\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0146 - mae: 0.0839\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0268 - mae: 0.1025\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0113 - mae: 0.0778\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0195 - mae: 0.0905\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.1034\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0180 - mae: 0.0811\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.0918\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0137 - mae: 0.0658\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0649\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0820\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0742\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0790\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0378 - mae: 0.1021\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0138 - mae: 0.0762\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0171 - mae: 0.0904\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0125 - mae: 0.0795\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0196 - mae: 0.0830\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0146 - mae: 0.0781\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0920\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0832\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0188 - mae: 0.0885\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0134 - mae: 0.0710\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0303 - mae: 0.1043\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0157 - mae: 0.0837\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0143 - mae: 0.0771\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0403 - mae: 0.1048\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0253 - mae: 0.0935\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0133 - mae: 0.0859\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0135 - mae: 0.0736\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.0921\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.0849\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0133 - mae: 0.0688\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0105 - mae: 0.0693\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0760\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0867\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0132 - mae: 0.0788\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cd8da170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1508 - mae: 0.2732\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.6028 - mae: 0.5414\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.2749 - mae: 0.3386\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.2066\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0731 - mae: 0.2004\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1175 - mae: 0.2122\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0482 - mae: 0.1650\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0437 - mae: 0.1588\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0365 - mae: 0.1316\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0344 - mae: 0.1322\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0459 - mae: 0.1479\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0642 - mae: 0.1673\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0503 - mae: 0.1564\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0405 - mae: 0.1550\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0387 - mae: 0.1303\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0282 - mae: 0.1292\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0330 - mae: 0.1275\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0323 - mae: 0.1195\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0174 - mae: 0.0971\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0352 - mae: 0.1311\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0475 - mae: 0.1394\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0850\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0368 - mae: 0.1280\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.0917\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0348 - mae: 0.1398\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0387 - mae: 0.1237\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.1018\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0414 - mae: 0.1268\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0291 - mae: 0.1144\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0282 - mae: 0.1087\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0287 - mae: 0.1074\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0788 - mae: 0.1601\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0230 - mae: 0.0974\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0362 - mae: 0.1220\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0311 - mae: 0.1086\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0261 - mae: 0.1220\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0313 - mae: 0.1090\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.1015\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0203 - mae: 0.0958\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1002\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0289 - mae: 0.1146\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0431 - mae: 0.1302\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0441 - mae: 0.1292\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0299 - mae: 0.1228\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1035\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0215 - mae: 0.1003\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0239 - mae: 0.1025\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0193 - mae: 0.0896\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0248 - mae: 0.1015\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0290 - mae: 0.1108\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0214 - mae: 0.0922\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0351 - mae: 0.1195\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0228 - mae: 0.0956\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0149 - mae: 0.0833\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.0980\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0178 - mae: 0.0940\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0223 - mae: 0.0909\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0217 - mae: 0.0984\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0254 - mae: 0.0936\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0187 - mae: 0.0679\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0260 - mae: 0.1076\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0299 - mae: 0.1068\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0205 - mae: 0.0984\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0175 - mae: 0.0881\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0277 - mae: 0.1184\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0155 - mae: 0.0881\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0253 - mae: 0.1001\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0166 - mae: 0.0833\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0149 - mae: 0.0833\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0179 - mae: 0.0926\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0195 - mae: 0.0885\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0220 - mae: 0.0977\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0133 - mae: 0.0758\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0291 - mae: 0.0974\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0315 - mae: 0.1004\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0234 - mae: 0.0961\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0336 - mae: 0.1278\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0179 - mae: 0.0814\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0926\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0209 - mae: 0.0893\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0129 - mae: 0.0793\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0255 - mae: 0.1103\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0181 - mae: 0.0826\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0210 - mae: 0.0934\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0201 - mae: 0.0899\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0292 - mae: 0.0995\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0171 - mae: 0.0779\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0921\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0290 - mae: 0.1069\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.0972\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0191 - mae: 0.0883\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0181 - mae: 0.0894\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0141 - mae: 0.0794\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0273 - mae: 0.1081\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0148 - mae: 0.0803\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0792\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0198 - mae: 0.0910\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0652\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0290 - mae: 0.0949\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0115 - mae: 0.0639\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0126 - mae: 0.0815\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87c80184d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2009 - mae: 0.3027\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "108/108 [==============================] - 1s 1ms/step - loss: 0.3830 - mae: 0.4824\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1137 - mae: 0.2333\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1236 - mae: 0.2482\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0828 - mae: 0.2084\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0573 - mae: 0.1520\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.1071 - mae: 0.2128\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0666 - mae: 0.1571\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0451 - mae: 0.1464\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0482 - mae: 0.1639\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0420 - mae: 0.1363\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0365 - mae: 0.1558\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0360 - mae: 0.1424\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0384 - mae: 0.1338\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0353 - mae: 0.1294\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0414 - mae: 0.1418\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0506 - mae: 0.1603\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0307 - mae: 0.1126\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0353 - mae: 0.1267\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0293 - mae: 0.1133\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0278 - mae: 0.1180\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.1240\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0296 - mae: 0.1240\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0246 - mae: 0.1083\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0283 - mae: 0.1235\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.1082\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0313 - mae: 0.1306\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0290 - mae: 0.1204\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0376 - mae: 0.1285\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0339 - mae: 0.1313\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0193 - mae: 0.0979\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0155 - mae: 0.0919\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0470 - mae: 0.1373\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0204 - mae: 0.1047\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0147 - mae: 0.0856\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0241 - mae: 0.1129\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0398 - mae: 0.1229\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0205 - mae: 0.0936\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0251 - mae: 0.0932\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0151 - mae: 0.0906\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0163 - mae: 0.0994\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0176 - mae: 0.0945\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0278 - mae: 0.1227\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0185 - mae: 0.0994\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0201 - mae: 0.0877\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0208 - mae: 0.0995\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0171 - mae: 0.0928\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0193 - mae: 0.0923\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0136 - mae: 0.0779\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0165 - mae: 0.0801\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0214 - mae: 0.1092\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0202 - mae: 0.1013\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0128 - mae: 0.0861\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0178 - mae: 0.0790\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0915\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0235 - mae: 0.0926\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0215 - mae: 0.0883\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0171 - mae: 0.0941\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0123 - mae: 0.0831\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0339 - mae: 0.1060\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0861\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0246 - mae: 0.1059\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0176 - mae: 0.0957\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0897\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0897\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0134 - mae: 0.0808\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0139 - mae: 0.0857\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0175 - mae: 0.0928\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0287 - mae: 0.1134\n",
            "Epoch 69/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0747\n",
            "Epoch 70/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.0896\n",
            "Epoch 71/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0221 - mae: 0.0980\n",
            "Epoch 72/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0140 - mae: 0.0837\n",
            "Epoch 73/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0132 - mae: 0.0788\n",
            "Epoch 74/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0140 - mae: 0.0781\n",
            "Epoch 75/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0258 - mae: 0.0993\n",
            "Epoch 76/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0824\n",
            "Epoch 77/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.0951\n",
            "Epoch 78/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0219 - mae: 0.1039\n",
            "Epoch 79/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.0921\n",
            "Epoch 80/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0318 - mae: 0.1052\n",
            "Epoch 81/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0107 - mae: 0.0770\n",
            "Epoch 82/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0760\n",
            "Epoch 83/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0689\n",
            "Epoch 84/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0227 - mae: 0.1013\n",
            "Epoch 85/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0165 - mae: 0.0861\n",
            "Epoch 86/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0117 - mae: 0.0717\n",
            "Epoch 87/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0119 - mae: 0.0703\n",
            "Epoch 88/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0148 - mae: 0.0793\n",
            "Epoch 89/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0214 - mae: 0.0969\n",
            "Epoch 90/100\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.0906\n",
            "Epoch 91/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0182 - mae: 0.1004\n",
            "Epoch 92/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0127 - mae: 0.0747\n",
            "Epoch 93/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0122 - mae: 0.0736\n",
            "Epoch 94/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0103 - mae: 0.0665\n",
            "Epoch 95/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0138 - mae: 0.0790\n",
            "Epoch 96/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0125 - mae: 0.0749\n",
            "Epoch 97/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0084 - mae: 0.0632\n",
            "Epoch 98/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0178 - mae: 0.0838\n",
            "Epoch 99/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0110 - mae: 0.0676\n",
            "Epoch 100/100\n",
            "108/108 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0784\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87d4c79e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0664 - mae: 0.1892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqQ4yyP0HNGD"
      },
      "source": [
        "average_mae_history_drop = [np.mean([x[i] for x in all_mae_histories_drop]) for i in range(num_epochs)]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "TdKoslaGHrmf",
        "outputId": "156af377-7ee2-478f-ebf2-4da3252fc02b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, len(average_mae_history_drop) + 1), average_mae_history_drop)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9khLMirH2FI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df96624c-fadb-4691-9250-abb70843c946"
      },
      "source": [
        "model_tanh = build_model('tanh')\n",
        "model_tanh.fit(x_train, y_train,epochs= 100, batch_size=1, verbose=1)\n",
        "test_mse_score, test_mae_score = model_tanh.evaluate(x_test, y_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "143/143 [==============================] - 1s 1ms/step - loss: 0.4425 - mae: 0.5195\n",
            "Epoch 2/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.2672 - mae: 0.3735\n",
            "Epoch 3/100\n",
            "143/143 [==============================] - 0s 987us/step - loss: 0.2316 - mae: 0.3362\n",
            "Epoch 4/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.1664 - mae: 0.2913\n",
            "Epoch 5/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.1284 - mae: 0.2668\n",
            "Epoch 6/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.1364 - mae: 0.2806\n",
            "Epoch 7/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.1729 - mae: 0.2895\n",
            "Epoch 8/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.1082 - mae: 0.2601\n",
            "Epoch 9/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0742 - mae: 0.2014\n",
            "Epoch 10/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.1122 - mae: 0.2627\n",
            "Epoch 11/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0632 - mae: 0.1883\n",
            "Epoch 12/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0623 - mae: 0.1905\n",
            "Epoch 13/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0622 - mae: 0.1971\n",
            "Epoch 14/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0759 - mae: 0.1991\n",
            "Epoch 15/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0788 - mae: 0.1949\n",
            "Epoch 16/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0772 - mae: 0.2106\n",
            "Epoch 17/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0699 - mae: 0.2065\n",
            "Epoch 18/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0762 - mae: 0.2085\n",
            "Epoch 19/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0502 - mae: 0.1744\n",
            "Epoch 20/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0659 - mae: 0.1907\n",
            "Epoch 21/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0382 - mae: 0.1555\n",
            "Epoch 22/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0574 - mae: 0.1714\n",
            "Epoch 23/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0506 - mae: 0.1737\n",
            "Epoch 24/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0409 - mae: 0.1613\n",
            "Epoch 25/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0574 - mae: 0.1829\n",
            "Epoch 26/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0438 - mae: 0.1567\n",
            "Epoch 27/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0474 - mae: 0.1683\n",
            "Epoch 28/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0493 - mae: 0.1814\n",
            "Epoch 29/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0422 - mae: 0.1625\n",
            "Epoch 30/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0354 - mae: 0.1399\n",
            "Epoch 31/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0346 - mae: 0.1444\n",
            "Epoch 32/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0483 - mae: 0.1656\n",
            "Epoch 33/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0332 - mae: 0.1382\n",
            "Epoch 34/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0400 - mae: 0.1497\n",
            "Epoch 35/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.1271\n",
            "Epoch 36/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0296 - mae: 0.1223\n",
            "Epoch 37/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.1625\n",
            "Epoch 38/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0326 - mae: 0.1418\n",
            "Epoch 39/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0458 - mae: 0.1605\n",
            "Epoch 40/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0412 - mae: 0.1480\n",
            "Epoch 41/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0343 - mae: 0.1478\n",
            "Epoch 42/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0317 - mae: 0.1313\n",
            "Epoch 43/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0328 - mae: 0.1397\n",
            "Epoch 44/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0343 - mae: 0.1288\n",
            "Epoch 45/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0326 - mae: 0.1253\n",
            "Epoch 46/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0412 - mae: 0.1451\n",
            "Epoch 47/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0400 - mae: 0.1528\n",
            "Epoch 48/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0472 - mae: 0.1623\n",
            "Epoch 49/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0289 - mae: 0.1253\n",
            "Epoch 50/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0322 - mae: 0.1313\n",
            "Epoch 51/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0392 - mae: 0.1432\n",
            "Epoch 52/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0374 - mae: 0.1380\n",
            "Epoch 53/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.1226\n",
            "Epoch 54/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0310 - mae: 0.1344\n",
            "Epoch 55/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0217 - mae: 0.1134\n",
            "Epoch 56/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0403 - mae: 0.1525\n",
            "Epoch 57/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1216\n",
            "Epoch 58/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0278 - mae: 0.1263\n",
            "Epoch 59/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0267 - mae: 0.1084\n",
            "Epoch 60/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.1229\n",
            "Epoch 61/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0314 - mae: 0.1392\n",
            "Epoch 62/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.1171\n",
            "Epoch 63/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.1066\n",
            "Epoch 64/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0385 - mae: 0.1418\n",
            "Epoch 65/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0341 - mae: 0.1306\n",
            "Epoch 66/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0255 - mae: 0.1238\n",
            "Epoch 67/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0196 - mae: 0.1082\n",
            "Epoch 68/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0255 - mae: 0.1233\n",
            "Epoch 69/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0315 - mae: 0.1308\n",
            "Epoch 70/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0348 - mae: 0.1373\n",
            "Epoch 71/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0228 - mae: 0.1135\n",
            "Epoch 72/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0257 - mae: 0.1123\n",
            "Epoch 73/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0240 - mae: 0.1122\n",
            "Epoch 74/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0252 - mae: 0.1177\n",
            "Epoch 75/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0283 - mae: 0.1218\n",
            "Epoch 76/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0360 - mae: 0.1385\n",
            "Epoch 77/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0216 - mae: 0.1180\n",
            "Epoch 78/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0250 - mae: 0.1070\n",
            "Epoch 79/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0196 - mae: 0.0976\n",
            "Epoch 80/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0275 - mae: 0.1177\n",
            "Epoch 81/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0206 - mae: 0.1140\n",
            "Epoch 82/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0165 - mae: 0.1004\n",
            "Epoch 83/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1145\n",
            "Epoch 84/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.1012\n",
            "Epoch 85/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0166 - mae: 0.0929\n",
            "Epoch 86/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0208 - mae: 0.1008\n",
            "Epoch 87/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0237 - mae: 0.1128\n",
            "Epoch 88/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0305 - mae: 0.1357\n",
            "Epoch 89/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0327 - mae: 0.1272\n",
            "Epoch 90/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.0999\n",
            "Epoch 91/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0225 - mae: 0.1012\n",
            "Epoch 92/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0149 - mae: 0.0954\n",
            "Epoch 93/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0403 - mae: 0.1204\n",
            "Epoch 94/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.1058\n",
            "Epoch 95/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0190 - mae: 0.0982\n",
            "Epoch 96/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0220 - mae: 0.1078\n",
            "Epoch 97/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.1111\n",
            "Epoch 98/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0225 - mae: 0.1064\n",
            "Epoch 99/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0939\n",
            "Epoch 100/100\n",
            "143/143 [==============================] - 0s 1ms/step - loss: 0.0238 - mae: 0.1018\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cd8dab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1979 - mae: 0.2544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP7Tre4Kl1Hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ab2404-c0d4-450b-a53f-0bab071332a3"
      },
      "source": [
        "model_relu = build_model('relu')\n",
        "model_relu.fit(x_train, y_train,epochs= 100, batch_size=1, verbose=0)\n",
        "test_mse_score, test_mae_score = model_relu.evaluate(x_test, y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cd973440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2377 - mae: 0.2557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP445FpQ9kZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903bb07d-b1ca-42aa-bf65-5a326a1a7709"
      },
      "source": [
        "model_regular = build_model_regular('relu')\n",
        "model_regular.fit(x_train, y_train,epochs= 100, batch_size=1, verbose=0)\n",
        "test_mse_score, test_mae_score = model_regular.evaluate(x_test, y_test)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87cc62f4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2512 - mae: 0.2490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiEK7Phb-jwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352cfe10-0807-4c67-f575-15332c27c75c"
      },
      "source": [
        "model_drop = build_model_drop('relu')\n",
        "model_drop.fit(x_train, y_train,epochs= 100, batch_size=1, verbose=0)\n",
        "test_mse_score, test_mae_score = model_drop.evaluate(x_test, y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f87ccf7f0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4968 - mae: 0.3900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "folonsJWVSYR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}